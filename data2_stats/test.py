import json
import os
import scrapy
import requests

# if os.path.isfile("C:\\Users\\lwang.leiwang\\Downloads\\数据导出.csv"):
#     print("ok")
# else:
#     print("?")

# f = urllib2.urlopen("http://43.248.49.97/queryData/downloadQueryData?pageNum=1&pageSize=10&year=2019&monthFlag=&codeTsFlag=true&codeLength=8&outerField1=CODE_TS&outerField2=ORIGIN_COUNTRY&outerField3=TRADE_MODE&outerField4=TRADE_CO_PORT&outerValue2=101%2C102%2C103%2C104%2C105%2C106%2C107%2C108%2C109%2C110%2C111%2C112%2C113%2C114%2C115%2C116%2C117%2C118%2C119%2C120%2C121%2C122%2C123%2C124%2C125%2C126%2C127%2C128%2C129%2C130%2C131%2C132%2C133%2C134%2C135%2C136%2C137%2C138%2C139%2C141%2C142%2C143%2C144%2C145%2C146%2C147%2C148%2C149%2C199%2C201%2C202%2C203%2C204%2C205%2C206%2C207%2C208%2C209%2C210%2C211%2C212%2C213%2C214%2C215%2C216%2C217%2C218%2C219%2C220%2C221%2C222%2C223%2C224%2C225%2C226%2C227%2C228%2C229%2C230%2C231%2C232%2C233%2C234%2C235%2C236%2C237%2C238%2C239%2C240%2C241%2C242%2C243%2C244%2C245%2C246%2C247%2C248%2C249%2C250%2C251%2C252%2C253%2C254%2C255%2C256%2C257%2C258%2C259%2C260%2C299%2C301%2C302%2C303%2C304%2C305%2C306%2C307%2C308%2C309%2C310%2C311%2C312%2C313%2C314%2C315%2C316%2C318%2C320%2C321%2C322%2C323%2C324%2C325%2C326%2C327%2C328%2C329%2C330%2C331%2C334%2C335%2C336%2C337%2C338%2C339%2C340%2C343%2C344%2C347%2C349%2C350%2C351%2C352%2C353%2C354%2C355%2C356%2C357%2C358%2C359%2C399%2C401%2C402%2C403%2C404%2C405%2C406%2C408%2C409%2C410%2C411%2C412%2C413%2C414%2C415%2C416%2C417%2C418%2C419%2C420%2C421%2C422%2C423%2C424%2C425%2C426%2C427%2C428%2C429%2C430%2C431%2C432%2C433%2C434%2C435%2C436%2C437%2C438%2C439%2C440%2C441%2C442%2C443%2C444%2C445%2C446%2C447%2C448%2C449%2C499%2C501%2C502%2C503%2C504%2C599%2C601%2C602%2C603%2C604%2C605%2C606%2C607%2C608%2C609%2C610%2C611%2C612%2C613%2C614%2C615%2C616%2C617%2C618%2C619%2C620%2C621%2C622%2C623%2C625%2C699%2C701%2C702&outerValue3=10%2C11%2C12%2C13%2C14%2C15%2C16%2C19%2C20%2C22%2C23%2C25%2C27%2C30%2C31%2C33%2C34%2C35%2C39%2C41&outerValue4=11%2C12%2C13%2C14%2C15%2C21%2C22%2C23%2C31%2C32%2C33%2C34%2C35%2C36%2C37%2C41%2C42%2C43%2C44%2C45%2C46%2C50%2C51%2C52%2C53%2C54%2C61%2C62%2C63%2C64%2C65&orderType=CODE+ASC&outerValue1=01061221%2C01061229%2C01061310%2C01061390%2C01061410%2C01061490%2C01061910%2C01061990%2C01062011%2C01062019%2C01062020%2C01062090%2C01063110%2C01063190%2C01063210%2C01063290%2C01063310%2C01063390%2C01063910%2C01063921&startMonth=1&endMonth=2&iEType=0&currencyType=rmb")
# with open("test.csv", "wb") as code:
#     code.write(f.read())

# print("start")
# r = requests.get("http://43.248.49.97/queryData/downloadQueryData?pageNum=1&pageSize=10&year=2019&monthFlag=&codeTsFlag=true&codeLength=8&outerField1=CODE_TS&outerField2=ORIGIN_COUNTRY&outerField3=TRADE_MODE&outerField4=TRADE_CO_PORT&outerValue2=101%2C102%2C103%2C104%2C105%2C106%2C107%2C108%2C109%2C110%2C111%2C112%2C113%2C114%2C115%2C116%2C117%2C118%2C119%2C120%2C121%2C122%2C123%2C124%2C125%2C126%2C127%2C128%2C129%2C130%2C131%2C132%2C133%2C134%2C135%2C136%2C137%2C138%2C139%2C141%2C142%2C143%2C144%2C145%2C146%2C147%2C148%2C149%2C199%2C201%2C202%2C203%2C204%2C205%2C206%2C207%2C208%2C209%2C210%2C211%2C212%2C213%2C214%2C215%2C216%2C217%2C218%2C219%2C220%2C221%2C222%2C223%2C224%2C225%2C226%2C227%2C228%2C229%2C230%2C231%2C232%2C233%2C234%2C235%2C236%2C237%2C238%2C239%2C240%2C241%2C242%2C243%2C244%2C245%2C246%2C247%2C248%2C249%2C250%2C251%2C252%2C253%2C254%2C255%2C256%2C257%2C258%2C259%2C260%2C299%2C301%2C302%2C303%2C304%2C305%2C306%2C307%2C308%2C309%2C310%2C311%2C312%2C313%2C314%2C315%2C316%2C318%2C320%2C321%2C322%2C323%2C324%2C325%2C326%2C327%2C328%2C329%2C330%2C331%2C334%2C335%2C336%2C337%2C338%2C339%2C340%2C343%2C344%2C347%2C349%2C350%2C351%2C352%2C353%2C354%2C355%2C356%2C357%2C358%2C359%2C399%2C401%2C402%2C403%2C404%2C405%2C406%2C408%2C409%2C410%2C411%2C412%2C413%2C414%2C415%2C416%2C417%2C418%2C419%2C420%2C421%2C422%2C423%2C424%2C425%2C426%2C427%2C428%2C429%2C430%2C431%2C432%2C433%2C434%2C435%2C436%2C437%2C438%2C439%2C440%2C441%2C442%2C443%2C444%2C445%2C446%2C447%2C448%2C449%2C499%2C501%2C502%2C503%2C504%2C599%2C601%2C602%2C603%2C604%2C605%2C606%2C607%2C608%2C609%2C610%2C611%2C612%2C613%2C614%2C615%2C616%2C617%2C618%2C619%2C620%2C621%2C622%2C623%2C625%2C699%2C701%2C702&outerValue3=10%2C11%2C12%2C13%2C14%2C15%2C16%2C19%2C20%2C22%2C23%2C25%2C27%2C30%2C31%2C33%2C34%2C35%2C39%2C41&outerValue4=11%2C12%2C13%2C14%2C15%2C21%2C22%2C23%2C31%2C32%2C33%2C34%2C35%2C36%2C37%2C41%2C42%2C43%2C44%2C45%2C46%2C50%2C51%2C52%2C53%2C54%2C61%2C62%2C63%2C64%2C65&orderType=CODE+ASC&outerValue1=01061221%2C01061229%2C01061310%2C01061390%2C01061410%2C01061490%2C01061910%2C01061990%2C01062011%2C01062019%2C01062020%2C01062090%2C01063110%2C01063190%2C01063210%2C01063290%2C01063310%2C01063390%2C01063910%2C01063921&startMonth=1&endMonth=2&iEType=0&currencyType=rmb")
# with open("test.csv", "wb") as code:
#     code.write(r.content)
# print("end")
from scrapy.http import TextResponse

# s = TextResponse('')
# print(s)

# flag = (1==1)
# print(flag)

# with open("test.txt", "a") as file:
#     file.writelines("1")
# file.close()
#
# with open("test.txt", "a") as file:
#     file.writelines("2")
# file.close()

# d = {"aa": "sdfs"}
# with open("aaaa.txt", "wt") as f:
#     json.dump(d, f)
# f.close()


# 读取json串 > dict
d = {}
with open("test.txt", "rt", encoding="UTF-8") as f:
    d = json.load(f)
f.close()
print(d)
print(d['returndata'])
print(d['returndata']['wdnodes'])
print(d['returndata']['wdnodes'][0])
print(d['returndata']['wdnodes'][0]['nodes'])

# 具体指标
wdnodes = d['returndata']['wdnodes'][0]['nodes']
# 具体数据
datanodes = d['returndata']['datanodes']
for str in wdnodes:
    print(str['code'] + "," + str['name'])
    for datastr in datanodes:
        if datastr['code'].find(str['code']) > 0:
            print("    "+datastr['code'])
            print("    %d" % datastr['data']['data'])




